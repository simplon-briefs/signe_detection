
## Contexte du projet
Beaucoup de progrès et de recherches en IA ont été faites pour aider les personnes sourdes et muettes. L'apprentissage profond et la vision par ordinateur peuvent également être utilisés pour avoir un impact sur cette cause.

Cela peut être très utile pour les personnes sourdes et muettes dans la communication avec les autres car la connaissance de la langue des signes n'est pas quelque chose qui est commun à tous, de plus, cela peut être étendu à la création des éditeurs automatiques, où la personne peut facilement écrire par ses simples gestes .

## Modalités d'évaluation

*    Un rapport sur le projet réalisé qui explique les différentes étapes du code
*   Description des données
*    Présentation de l'architecture utilisée
*    Conclusion (avantages et inconvénients, concurrents, recommandations…)
*    Revue de code avec le formateur.

# signe_detection

Guillaume-Luigi-Christian

## Introduction

Dans le but de pouvoir faciliter la communication avec les personnes sourdes et muettes, nous avons décidé de mettre un place un système d'intelligence artificielle  capable de comprehension et de transcription du langage des signes. Pour ce faire nous avons mis en place différentes  étapes.

## Création du dataset

Des images de plusieurs classes (A,B,c....W,X,Y,Z) correspondant aux différentes lettre de l'alphabet on été générées ensuite labelisée avec **Labelimage** par les différents groupes d'apprenants,  pour les préparer avant l'entraînement du modèle. Nous avons utilisées des mains de différentes couleurs (blanches et noires) afin que le modèle n'ait pas de soucis de reconnaissance dû à la couleur.

## Partie détection 


































































# Rendu final
![image](/images.png)
